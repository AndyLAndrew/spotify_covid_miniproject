{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001B[0;31mSystemExit\u001B[0m\u001B[0;31m:\u001B[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Andrew/Documents/School/Spring 2023 Graduate UCSD/COGS 209/spotify_covid_miniproject/environment/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3516: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# import statements + data load\n",
    "import pandas as pd, numpy as np, seaborn as sns, matplotlib.pyplot as plt\n",
    "spotify_dth = pd.read_csv(\"data/charts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# basic data cleaning/type conversions\n",
    "indexes = range(0, len(spotify_dth)) # index\n",
    "# converting to datetime\n",
    "spotify_dth['date'] = pd.to_datetime(spotify_dth['date'], format='%Y-%m-%d')\n",
    "\n",
    "# dropping all rows that did not make the #1 spot\n",
    "#spotify_dth = [row for index, row in tqdm(spotify_dth.iterrows(), total=len(spotify_dth)) if row['rank'] == 1]\n",
    "spotify_dth = spotify_dth.drop([index for index, row in spotify_dth.iterrows() if row['rank'] != 1])\n",
    "\n",
    "\n",
    "# dropping all rows that are not in the US\n",
    "spotify_dth_US = spotify_dth.drop([index for index, row in spotify_dth.iterrows() if row['region'] != 'United States'])\n",
    "#spotify_dth_US = [row for index, row in tqdm(spotify_dth.iterrows(), total=len(spotify_dth)) if row['region'] == 'United States']\n",
    "\n",
    "\n",
    "# resetting indeces of both\n",
    "spotify_dth.reset_index(inplace=True, drop=True)\n",
    "spotify_dth_US.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# saving to csv for reference\n",
    "spotify_dth.to_csv(\"data/number_one_all_regions_2017_2021.csv\", index=False)\n",
    "spotify_dth_US.to_csv(\"data/number_one_US_2017_2021.csv\", index=False)\n",
    "del spotify_dth # removing var to free up memory\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# now reading all of the data from the prior project group\n",
    "years = [2017, 2018, 2019, 2020, 2021]\n",
    "spotify_dict = {}\n",
    "for year in years:\n",
    "    temp_df_name = \"spotify_\" + str(year) # concatenating df name\n",
    "    temp_df_directory = \"data/\" + str(year) + \"_complete\" + \".csv\" # concatenating directory name\n",
    "    spotify_dict[temp_df_name] = pd.read_csv(temp_df_directory) # adding df to dict\n",
    "    spotify_dict[temp_df_name].drop(['Unnamed: 0', 'Streams'], axis=1, inplace=True) # dropping index col\n",
    "    spotify_dict[temp_df_name][\"year\"] = year # adding identifying year column\n",
    "\n",
    "# concatenating into a single df\n",
    "spotify_2017_2021 = pd.concat(spotify_dict.values(), ignore_index=True)\n",
    "# dropping duplicate songs (if from the same artist)\n",
    "spotify_2017_2021.drop_duplicates(['Song Names', 'Artists'], keep='first', inplace=True)\n",
    "spotify_2017_2021.reset_index(inplace=True, drop=True) # resetting index\n",
    "# renaming song title and artist\n",
    "spotify_2017_2021.rename(columns={'Song Names': 'title', 'Artists':'artist'}, inplace=True)\n",
    "\n",
    "# merging in extra features from group's df\n",
    "spotify_merged = spotify_dth_US.merge(spotify_2017_2021[['title', 'artist', 'Danceability', 'Energy', 'Key', 'Loudness',\n",
    "                                                    'Mode', 'Speechiness', 'Acousticness', 'Instrumentalness', 'Liveness',\n",
    "                                                    'Valence', 'Tempo', 'Time Signature', 'year']], on=['title', 'artist'], how='left')\n",
    "\n",
    "# dropping NA's we acquired (aka drops rows we cannot get extra features for)\n",
    "spotify_merged.dropna(subset=['Danceability'], inplace=True)\n",
    "spotify_merged.reset_index(inplace=True, drop=True) # resetting index\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of streams included: 1257 \n",
      "length of streams dropped: 1592\n"
     ]
    }
   ],
   "source": [
    "# so with 335 NAs in streams, we have two options\n",
    "# include stream count to also account for streaming amount\n",
    "# or drop the feature and assume only the genre, danceability, etc. + the covid timeline are what matter...\n",
    "# let's split it into two dfs and simply try both\n",
    "spotify_merged_streams_incl = spotify_merged.dropna(subset=['streams'], inplace=False).copy()\n",
    "spotify_merged_streams_dropped = spotify_merged.drop(['streams'], axis=1, inplace=False).copy()\n",
    "\n",
    "# resetting index again\n",
    "spotify_merged_streams_incl.reset_index(inplace=True, drop=True)\n",
    "spotify_merged_streams_dropped.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print(\"length of streams included:\",len(spotify_merged_streams_incl),\"\\nlength of streams dropped:\", len(spotify_merged_streams_dropped))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'str' and 'Timestamp'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 10\u001B[0m\n\u001B[1;32m      8\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;241m3\u001B[39m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m# Creating new column based on the dates\u001B[39;00m\n\u001B[0;32m---> 10\u001B[0m spotify_merged_streams_incl\u001B[38;5;241m.\u001B[39mloc[:, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcovid_period\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mspotify_merged_streams_incl\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdate\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmap_dates_to_values\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m spotify_merged_streams_dropped\u001B[38;5;241m.\u001B[39mloc[:, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcovid_period\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m spotify_merged_streams_dropped[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdate\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(map_dates_to_values)\n",
      "File \u001B[0;32m~/Documents/School/Spring 2023 Graduate UCSD/COGS 209/spotify_covid_miniproject/environment/lib/python3.9/site-packages/pandas/core/series.py:4626\u001B[0m, in \u001B[0;36mSeries.apply\u001B[0;34m(self, func, convert_dtype, args, **kwargs)\u001B[0m\n\u001B[1;32m   4516\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply\u001B[39m(\n\u001B[1;32m   4517\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   4518\u001B[0m     func: AggFuncType,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4521\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   4522\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m Series:\n\u001B[1;32m   4523\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   4524\u001B[0m \u001B[38;5;124;03m    Invoke function on values of Series.\u001B[39;00m\n\u001B[1;32m   4525\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4624\u001B[0m \u001B[38;5;124;03m    dtype: float64\u001B[39;00m\n\u001B[1;32m   4625\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 4626\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mSeriesApply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/School/Spring 2023 Graduate UCSD/COGS 209/spotify_covid_miniproject/environment/lib/python3.9/site-packages/pandas/core/apply.py:1025\u001B[0m, in \u001B[0;36mSeriesApply.apply\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1022\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_str()\n\u001B[1;32m   1024\u001B[0m \u001B[38;5;66;03m# self.f is Callable\u001B[39;00m\n\u001B[0;32m-> 1025\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/School/Spring 2023 Graduate UCSD/COGS 209/spotify_covid_miniproject/environment/lib/python3.9/site-packages/pandas/core/apply.py:1076\u001B[0m, in \u001B[0;36mSeriesApply.apply_standard\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1074\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1075\u001B[0m         values \u001B[38;5;241m=\u001B[39m obj\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mobject\u001B[39m)\u001B[38;5;241m.\u001B[39m_values\n\u001B[0;32m-> 1076\u001B[0m         mapped \u001B[38;5;241m=\u001B[39m \u001B[43mlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_infer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1077\u001B[0m \u001B[43m            \u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1078\u001B[0m \u001B[43m            \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1079\u001B[0m \u001B[43m            \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1080\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1082\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(mapped) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mapped[\u001B[38;5;241m0\u001B[39m], ABCSeries):\n\u001B[1;32m   1083\u001B[0m     \u001B[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001B[39;00m\n\u001B[1;32m   1084\u001B[0m     \u001B[38;5;66;03m#  See also GH#25959 regarding EA support\u001B[39;00m\n\u001B[1;32m   1085\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m obj\u001B[38;5;241m.\u001B[39m_constructor_expanddim(\u001B[38;5;28mlist\u001B[39m(mapped), index\u001B[38;5;241m=\u001B[39mobj\u001B[38;5;241m.\u001B[39mindex)\n",
      "File \u001B[0;32m~/Documents/School/Spring 2023 Graduate UCSD/COGS 209/spotify_covid_miniproject/environment/lib/python3.9/site-packages/pandas/_libs/lib.pyx:2834\u001B[0m, in \u001B[0;36mpandas._libs.lib.map_infer\u001B[0;34m()\u001B[0m\n",
      "Cell \u001B[0;32mIn[10], line 3\u001B[0m, in \u001B[0;36mmap_dates_to_values\u001B[0;34m(date)\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmap_dates_to_values\u001B[39m(date):\n\u001B[0;32m----> 3\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mdate\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m<\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_datetime\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m2019-03-01\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m:\n\u001B[1;32m      4\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m date \u001B[38;5;241m<\u001B[39m pd\u001B[38;5;241m.\u001B[39mto_datetime(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m2022-01-01\u001B[39m\u001B[38;5;124m'\u001B[39m):\n",
      "\u001B[0;31mTypeError\u001B[0m: '<' not supported between instances of 'str' and 'Timestamp'"
     ]
    }
   ],
   "source": [
    "# tracking covid period\n",
    "def map_dates_to_values(date):\n",
    "    if date < pd.to_datetime('2019-03-01'):\n",
    "        return 1\n",
    "    elif date < pd.to_datetime('2022-01-01'):\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "# Creating new column based on the dates\n",
    "spotify_merged_streams_incl.loc[:, 'covid_period'] = spotify_merged_streams_incl['date'].apply(map_dates_to_values)\n",
    "spotify_merged_streams_dropped.loc[:, 'covid_period'] = spotify_merged_streams_dropped['date'].apply(map_dates_to_values)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [
    "# let's go ahead and drop the \"title\", \"rank\", \"date\", \"artist\", \"url\", \"region\", \"chart\", \"trend\", \"year\" for each\n",
    "# we could come back to this and also try fitting into an nn to get character differences too per song/artist\n",
    "# as well, we could keep the date as well and try to predict the date or simply group (unsupervised)\n",
    "spotify_merged_streams_incl.drop([\"title\", \"rank\", \"date\", \"artist\", \"url\", \"region\", \"chart\", \"trend\", \"year\"], axis=1, inplace=True)\n",
    "spotify_merged_streams_dropped.drop([\"title\", \"rank\", \"date\", \"artist\", \"url\", \"region\", \"chart\", \"trend\", \"year\"], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# deleting unneeded dfs\n",
    "del spotify_dth_US, spotify_2017_2021, spotify_merged"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [],
   "source": [
    "# alright now it's time to push into the models...\n",
    "# other imports needed for ML and data cleaning\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelBinarizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# we can't use f1, or anything conf matrix metrics due to no probabilities\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc, make_scorer, roc_auc_score, ConfusionMatrixDisplay, f1_score, confusion_matrix, accuracy_score, classification_report, RocCurveDisplay\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, LearningCurveDisplay, learning_curve\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "outputs": [],
   "source": [
    "# just performing this split on the included streams, you can do the same for dropped\n",
    "\n",
    "# training and testing splits\n",
    "# Pull Y variable out which is balance\n",
    "X = spotify_merged_streams_incl.iloc[:, 0:13].to_numpy()\n",
    "y = spotify_merged_streams_incl.iloc[:, 13:14].to_numpy().flatten()\n",
    "\n",
    "# basic T/T/Split modeling due to large size of data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [
    {
     "data": {
      "text/plain": "((842, 13), (415, 13), (842,), (415,))"
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# debugging...\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [],
   "source": [
    "# my favorite frankenfunction\n",
    "\n",
    "def metrics_classification_scorer(y_train, y_test, y_pred, y_proba, show_stats = True, save_auc = False):\n",
    "    \"\"\"\n",
    "\n",
    "    :param y_test: your testing data\n",
    "    :param y_pred: your predictions generated from classifier\n",
    "    :param y_proba: your probabilities generated from classifier\n",
    "    :param show_stats: default is True, shows ROC Curve, and all other Metrics\n",
    "    :param save_auc: saves AUC score if desired (must write to variable)\n",
    "    :return: plots of ROC curve, Conf Matrix Metrics, and AUC Score\n",
    "    \"\"\"\n",
    "\n",
    "    label_binarizer = LabelBinarizer().fit(y_train)\n",
    "    y_onehot_test = label_binarizer.transform(y_test)\n",
    "    # y_onehot_test.shape  # (n_samples, n_classes)\n",
    "\n",
    "    if show_stats:\n",
    "        RocCurveDisplay.from_predictions(\n",
    "            y_onehot_test.ravel(),\n",
    "            y_proba.ravel(),\n",
    "            name=\"micro-average OvR\",\n",
    "            color=\"darkorange\",\n",
    "        )\n",
    "        plt.plot([0, 1], [0, 1], \"k--\", label=\"chance level (AUC = 0.5)\")\n",
    "        plt.axis(\"square\")\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.title(\"Micro-averaged One-vs-Rest\\nReceiver Operating Characteristic\")\n",
    "        plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.25))\n",
    "        plt.show()\n",
    "\n",
    "    micro_roc_auc_ovr = roc_auc_score(\n",
    "        y_test,\n",
    "        y_proba,\n",
    "        multi_class=\"ovr\",\n",
    "        average=\"micro\",\n",
    "    )\n",
    "\n",
    "    if show_stats:\n",
    "        print(f\"Micro-averaged One-vs-Rest ROC AUC score:\\n{micro_roc_auc_ovr:.2f}\\n\")\n",
    "        print(f\"Test Set Accuracy : {accuracy_score(y_test, y_pred) * 100} %\\n\")\n",
    "        print(f\"Classification Report : \\n\\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "\n",
    "    # saves auc score if desired\n",
    "    if save_auc: return micro_roc_auc_ovr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "outputs": [],
   "source": [
    "# let's try using a logit, max iterations needed to be raised due to terrible convergence rate\n",
    "# indicating this will not end with good test results...\n",
    "logit_fitted = LogisticRegression(max_iter = 1000).fit(X_train, y_train)\n",
    "logit_y_pred = logit_fitted.predict(X_test)\n",
    "logit_y_prob = logit_fitted.predict_proba(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "outputs": [],
   "source": [
    "metrics_classification_scorer(y_train, y_test, logit_y_pred, logit_y_prob, save_auc = False)\n",
    "# trying to debug here\n",
    "print(len(logit_y_prob), len(X_test), len(y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}